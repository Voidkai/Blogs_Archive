# 联邦学习讨论总结与技术预研

> 参考《联邦学习白皮书》

## 联邦学习定义与价值分析

### 简单定义与架构

- 模型训练数据保留在本地，多个参与者联合建模，共同获益
- 联邦学习的建模效果和将整个数据集放在一处建模的效果相同，或相差不大（数据用户对齐或特征对齐的条件下）
- 迁移学习是在用户或特征不对齐的情况下，也可以在数据间通过交换加密参数达到知识迁移的效果
- 各方无需共享数据资源，即数据不出本地，进行数据联合训练，建立共享的机器学习模型

联邦学习架构：

![FL arch](http://cdn.kaixuan.site/img/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%9E%B6%E6%9E%84%E5%9B%BE.png#vwid=560&vhei=476)

联邦学习系统约束条件：
$$
|V_{FED}-V_{SUM}|<\delta
$$
$V_{FED}$为联邦学习模型效果，$V_{SUM}$为传统方法模型效果，$\delta$为有界正数。

### 联邦学习的商用价值

- 带动跨领域的企业级数据合作
  - 更有效地训练模型辅助自身市场布局及策略优化从而提升竞争力。
- 催生基于联合建模的新业态和模式
  - 不断影响和改变合作中提供方、需求方的关系，重定义各方合作者身份、服务方式以及盈利方式。
- 降低技术提升成本和促进创新技术发展
  - 有助于创新性技术的进一步飞跃。

### FL与现有研究的关联

#### 与差分隐私等传统隐私保护方法的类比

联邦学习通过加密机制下（同态加密等）的参数交换方式保护用户数据隐私，并且其数据和模型本身不会进行传输，因此**在数据层面不存在泄露的可能**，也不违反更严格的数据包含上法案。
而差分隐私等方法则通过在数据中加噪音等方式直到第三方不能区分个体，使得数据无法被还原的概率较高，以此保护用户隐私。但是**本质上还是进行了原始数据的传输**，存在着潜在被攻击的可能。

#### 与分布式机器学习的区别

分布式机器学习一个典型例子是参数服务器，它将数据存储在分布式的工作节点上，通过一个中心式的调度节点调配数据分布和分配计算资源，以便更高效的获得最终的训练模型。
而联邦学习中，参与方对本地的数据具有完全的自治权限，去中心化系统中参与方可以自主选择何时加入联邦学习，因此联邦学习相对分布式机器学习的学习环境更复杂。另外联邦学习也是一种应对数据隐私保护的有效措施。

#### 与区块链的关系

区块链和联邦学习都是一种去中心化网络，都涉及到密码学、加密算法等基础技术。其中区块链涉及到的加密算法主要为哈希算法，以及一些公钥加密算法，而联邦学习主要采用的是同态加密等加密方式。
区块链上节点通过记账获得奖励，在联邦学习中，多个参与方通过学习提高模型想过，参考各方贡献来分配奖励。

#### 联邦学习与安全多方计算的关系

学术界已经开展利用安全多方计算来增强联邦学习的安全性研究。例如Bonawitz指出，可以利用安全多方计算以安全的方式计算来自用户设备的模型参数更新综合。


## 联邦学习分类

联邦学习分类：
![分类](http://cdn.kaixuan.site/img/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB.png#vwid=1168&vhei=338)

### 横向联邦学习

在两个数据集的用户特征重叠较多而用户重叠较少的情况下，数据集按照横向即用户维度切分，取出双方用户特征相同而用户不完全相同的那部分数据进行训练。

### 纵向联邦学习

在两个数据集的用户特征重叠较少而用户重叠较多的情况下，数据集按照纵向即特征维度切分，取出双方用户相同而特征不完全相同的那部分数据进行训练。

### 联邦迁移学习

两个数据集的用户与用户特征重叠都较少的情况下，我们不对数据进行切分，而利用迁移学习来客服数据或标签不足的情况，这种方法叫做联邦迁移学习。

## 联邦学习开源框架

- FATE
- TensorFlow Federated
- PaddleFL
- Pysyft

![联邦学习开源框架对比](http://cdn.kaixuan.site/img/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6%E5%AF%B9%E6%AF%94.png#vwid=1170&vhei=1408)

## 可能的结合方向

1. 联邦学习训练以及预测与区块链对节点的限制以及服务提供的收益方式相结合，以激励联邦学习参与方持续性的提供服务。
2. 借助区块链、边缘服务器以及多方安全计算解决联邦学习准备阶段中的数据对齐问题。